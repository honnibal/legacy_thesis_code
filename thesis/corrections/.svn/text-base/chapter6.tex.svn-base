% \documentclass[a4paper,10pt]{article}
% \usepackage[utf8x]{inputenc}
% 
% %opening
% \title{Chapter 6 Corrections}
% \author{Matthew Honnibal}
% 
% \begin{document}
% 
% \maketitle
% 
% \begin{abstract}
% 
% \end{abstract}

\chapter{Corrections to Chapter 6}

\section{Jason Baldridge}

\subsection{at least ones}

\emph{Corrected.}

\subsection{as it performs has lower accuracy}

\emph{Corrected.}

\subsection{exta}

\emph{Corrected.}

\subsection{misplaced figures in Table 6.7}

\emph{Fixed.}

\subsection{Fix table reference}

\emph{Fixed.}

\subsection{Fix system name in Table 6.13}

\emph{Fixed.}

\subsection{model which is generally less accurate DERIV model}

\emph{Corrected.}

\subsection{cite \citet{clark:emnlp04} for supertag annotation}

\emph{Done.}

\section{Mark Steedman}

\subsection{srategy}

\emph{Corrected.}

\subsection{More discussion of why it's more efficient}

\emph{Extended the discussion on this issue on page 136.}

\section{Stephen Clark}

\subsection{because they are conditioned}

\emph{Reworded this.}

\subsection{even a first-order baseline}

\emph{Reworded this to `even a very simple model'.}

\subsection{Describe beta mechanism once well}

\emph{Extended the description in the background chapter, on page 51.}

\subsection{millions of candidate analyses}

\emph{Removed `millions of'.}

\subsection{modified CKY algorithm}

\emph{Reworded this to simply say `generated by the grammar.}

\subsection{due to supertagging phase}

\emph{Reworded this.}

\subsection{Several corrections to \citet{clark:cl07} description}

\emph{This section has been revised to reflect a better understanding of the
\candc parser models. I have removed the implementation-tweaking experiments from
the thesis results, as they were an unnecessary distraction from the contribution.}

\subsubsection{We omit dependencies model}

\emph{Reworded the reference to this model:}

\begin{quote}
 The configuration we omit is the dependencies model without normal form or
seen-rules derivational constraints, labelled \emph{Dependency} in
\citet{clark:cl07} Table 6. We omit this configuration because it performs worse
than the other models on every dimension We follow \citepos{clark:cl07}
nomenclature in referring to the dependency model that makes use of derivation
constraints as the \emph{Hybrid} model.
\end{quote}

\subsubsection{In place of negative examples}

\emph{Removed the subsection this was part of, as it was included based on
exactly the misunderstanding pointed out here: if the use of derivation
constraints during training is always set up to match the runtime configuration,
then this is not a parameter of the training phase worth discussing --- and
indeed, I don't vary it in any of my experiments.}

\subsection{Elaborate on cluster for parser training implementation}

\emph{Noted that we used the \citet{clark:cl07} hardware, an 18-node Beowulf cluster
with up to 25\textsc{gb} of \textsc{ram} available.}

\subsection{performance trends upwards}

\emph{Reworded.}

\subsection{control of noisy derivations}

\emph{Fixed.}

\subsection{seen at least ones}

\emph{Fixed.}

\subsection{causing us to hit our memory limit}

\emph{This section has been revised, and no longer includes this.}

\subsection{as it performs has lower}

\emph{Fixed.}

\subsection{Caption of table 6.3}

\emph{Fixed.}

%\end{document}
